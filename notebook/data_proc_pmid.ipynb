{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from base_fns import get_local_folder\n",
    "os.chdir(os.path.dirname(get_local_folder()))\n",
    "\n",
    "import pandas as pd\n",
    "import tabulate as tb\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import random\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from tab\n",
    "\n",
    "with initialize(\n",
    "    version_base=None,\n",
    "    config_path=\"../cfg\",\n",
    "):\n",
    "    cfg = compose(config_name=\"main\")\n",
    "    \n",
    "np.random.seed(cfg.random.seed)\n",
    "random.seed(cfg.random.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "\n",
    "- CelloSaurus; postives, expert curated\n",
    "- GoogleScholar; negatives, expert curated, gold standard\n",
    "- LitSuggest; negatives, likely rejects from previous curation cycles, silver standard\n",
    "- Medline, pseudo negatives, random sample from Medline, bronze standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplcates from MEDLINE sample\n",
    "\n",
    "medline_temp = pd.read_json(cfg.data.raw.pmid.medline, lines=True)\n",
    "\n",
    "medline_temp = medline_temp.drop_duplicates()\n",
    "medline_temp.to_json(cfg.data.raw.pmid.medline, lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ORIGIN          SOURCE\n",
       "cellosaurus     1          22719\n",
       "cellosaurus_ab  1          10000\n",
       "googlescholar   0            475\n",
       "litsuggest      0            645\n",
       "medline         0         558603\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = Munch()\n",
    "for k, v in cfg.data.raw.pmid.items():\n",
    "    raw[k] = pd.read_json(v, lines=True)\n",
    "    raw[k]['ORIGIN'] = k\n",
    "\n",
    "# filter out curated PMIDs from random MEDELINE sample\n",
    "raw_curated = pd.concat([raw[k] for k in raw if k != 'medline'], axis=0)\n",
    "raw.medline = raw.medline[~raw.medline.PMID.isin(raw_curated.PMID)]\n",
    "\n",
    "raw_all = pd.concat([raw[k] for k in raw], axis=0)\n",
    "raw_all[['ORIGIN', 'SOURCE']].groupby('ORIGIN').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cellosaurus_AB contains a subset of postitive PMIDs from  Cellosaurus that were previously used to train a Litsuggest model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for duplicates in raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_all['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data\n",
    "- negatives; 300 PMIDs from Google Scholar\n",
    "- positives; 300 PMIDs from Cellosaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET  SOURCE  ORIGIN       \n",
       "test     0       googlescholar    300\n",
       "         1       cellosaurus      300\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "processed = Munch()\n",
    "N_TEST_NEG = 300\n",
    "test_neg = raw.googlescholar.sample(n=300)\n",
    "test_pos = raw.cellosaurus[~raw.cellosaurus['PMID'].isin(raw.cellosaurus_ab[\"PMID\"])].sample(n= test_neg.shape[0])\n",
    "\n",
    "processed.test = pd.concat([test_neg, test_pos]).sample(frac = 1)\n",
    "test_pmids = processed.test.PMID.tolist() \n",
    "processed.test['DATASET'] = \"test\"\n",
    "processed.test[['DATASET','ORIGIN', 'SOURCE']].groupby(['DATASET','SOURCE']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train data\n",
    "We will create to balanced training sets:\n",
    "- Train_silver; Smaller dataset inluding only a portion of the data from Cellosaurus. Negatives including only high quality data from Google Scholar(gold) and LitSuggest (silver).\n",
    "- Train_gold; Larger dataset incuding all data from Cellosaur. Negatives are extended with pseudo negatives from MEDLINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_silver\n",
    "- negatives \n",
    "    - all remaining PMIDs from Google Scholar (gold)\n",
    "    - all PMIDs from LitSuggest (silver)\n",
    "- positive\n",
    "    - matched sample from cellosaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET       SOURCE  ORIGIN       \n",
       "train_silver  0       litsuggest       645\n",
       "                      googlescholar    175\n",
       "              1       cellosaurus      820\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_silver_neg = pd.concat(\n",
    "    [raw.googlescholar[~raw.googlescholar.PMID.isin(test_pmids)], raw.litsuggest]\n",
    ")\n",
    "train_silver_pos = raw.cellosaurus[~raw.cellosaurus.PMID.isin(test_pmids)].sample(n=len(train_silver_neg))\n",
    "\n",
    "processed.train_silver = pd.concat([train_silver_neg, train_silver_pos]).sample(frac=1)\n",
    "train_silver_pmids = processed.train_silver.PMID.tolist()\n",
    "processed.train_silver[\"DATASET\"] = \"train_silver\"\n",
    "processed.train_silver[[\"DATASET\", \"ORIGIN\", \"SOURCE\"]].groupby(\n",
    "    [\"DATASET\", \"SOURCE\"]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overlap with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([processed.train_silver, processed.test], axis=0) ['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_bronze\n",
    "- negatives\n",
    "    - all remaining PMIDs from Google Scholar (gold)\n",
    "    - all PMIDs from LitSuggest (silver) \n",
    "    - matched sample of pseudo-negatives from MEDLINE (bronze)\n",
    "- positives\n",
    "    - all remaining PMIDs from Cellosaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET       SOURCE  ORIGIN       \n",
       "train_bronze  0       medline          21599\n",
       "                      litsuggest         645\n",
       "                      googlescholar      175\n",
       "              1       cellosaurus      22419\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bronze_pos = raw.cellosaurus[~raw.cellosaurus.PMID.isin(test_pmids)]\n",
    "\n",
    "train_bronze_neg = pd.concat([raw.googlescholar[~raw.googlescholar.PMID.isin(test_pmids)],raw.litsuggest])\n",
    "medline_n = train_bronze_pos.shape[0] - train_bronze_neg.shape[0]\n",
    "medline_sample = raw.medline[~raw.medline.PMID.isin(raw_curated.PMID)].sample(medline_n)\n",
    "train_bronze_neg = pd.concat([train_bronze_neg,medline_sample])\n",
    "# train_bronze_neg = pd.concat([train_bronze_neg,raw.medline.sample(n_sample_medline)])\n",
    "\n",
    "processed.train_bronze = pd.concat([train_bronze_neg, train_bronze_pos]).sample(frac=1)\n",
    "processed.train_bronze[\"DATASET\"] = \"train_bronze\"\n",
    "processed.train_bronze[[\"DATASET\", \"ORIGIN\", \"SOURCE\"]].groupby(\n",
    "    [\"DATASET\", \"SOURCE\"]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overlap with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([processed.train_bronze, processed.test], axis=0) ['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train_silver_**ab**\n",
    "- negatives \n",
    "    - all remaining PMIDs from Google Scholar (gold)\n",
    "    - all PMIDs from LitSuggest (silver)\n",
    "- positive\n",
    "    - matched sample from **cellosaurus_ab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET          SOURCE  ORIGIN        \n",
       "train_silver_ab  0       litsuggest        645\n",
       "                         googlescholar     175\n",
       "                 1       cellosaurus_ab    820\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_silver_ab_neg = pd.concat(\n",
    "    [raw.googlescholar[~raw.googlescholar.PMID.isin(test_pmids)], raw.litsuggest]\n",
    ")\n",
    "train_silver_ab_pos = raw.cellosaurus_ab[~raw.cellosaurus_ab.PMID.isin(test_pmids)].sample(n=len(train_silver_neg))\n",
    "\n",
    "processed.train_silver_ab = pd.concat([train_silver_ab_neg, train_silver_ab_pos]).sample(frac=1)\n",
    "train_silver_ab_pmids = processed.train_silver_ab.PMID.tolist()\n",
    "processed.train_silver_ab[\"DATASET\"] = \"train_silver_ab\"\n",
    "processed.train_silver_ab[[\"DATASET\", \"ORIGIN\", \"SOURCE\"]].groupby(\n",
    "    [\"DATASET\", \"SOURCE\"]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overlap with test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([processed.train_silver_ab, processed.test], axis=0) ['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_bronze_**ab**\n",
    "- negatives\n",
    "    - all remaining PMIDs from Google Scholar (gold)\n",
    "    - all PMIDs from LitSuggest (silver) \n",
    "    - matched sample of pseudo-negatives from MEDLINE (bronze)\n",
    "- positives\n",
    "    - all remaining PMIDs from **Cellosaurus_ab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET          SOURCE  ORIGIN        \n",
       "train_bronze_ab  0       medline            9180\n",
       "                         litsuggest          645\n",
       "                         googlescholar       175\n",
       "                 1       cellosaurus_ab    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bronze_ab_pos = raw.cellosaurus_ab[~raw.cellosaurus_ab.PMID.isin(test_pmids)]\n",
    "\n",
    "train_bronze_ab_neg = pd.concat([raw.googlescholar[~raw.googlescholar.PMID.isin(test_pmids)],raw.litsuggest])\n",
    "medline_n = train_bronze_ab_pos.shape[0] - train_bronze_ab_neg.shape[0]\n",
    "medline_sample = raw.medline[~raw.medline.PMID.isin(raw_curated.PMID)].sample(medline_n)\n",
    "train_bronze_ab_neg = pd.concat([train_bronze_ab_neg,medline_sample])\n",
    "# train_bronze_neg = pd.concat([train_bronze_neg,raw.medline.sample(n_sample_medline)])\n",
    "\n",
    "processed.train_bronze_ab = pd.concat([train_bronze_ab_neg, train_bronze_ab_pos]).sample(frac=1)\n",
    "processed.train_bronze_ab[\"DATASET\"] = \"train_bronze_ab\"\n",
    "processed.train_bronze_ab[[\"DATASET\", \"ORIGIN\", \"SOURCE\"]].groupby(\n",
    "    [\"DATASET\", \"SOURCE\"]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for overlap with test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([processed.train_bronze_ab, processed.test], axis=0) ['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_**ml_ab**\n",
    "Similar to Train_bronze_ml but without the negatives from the GoogleScholar or Litsuggest datasets.\n",
    "The dataset can be used to compare perfrommance of the new models compare to the origional Litsuggest model.\n",
    "\n",
    "- negatives\n",
    "    - matched sample of pseudo-negatives from MEDLINE (bronze)\n",
    "- positives\n",
    "    - all remaining PMIDs from **Cellosaurus_ab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATASET      SOURCE  ORIGIN        \n",
       "train_ml_ab  0       medline           10000\n",
       "             1       cellosaurus_ab    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ml_ab_pos = raw.cellosaurus_ab[~raw.cellosaurus_ab.PMID.isin(test_pmids)]\n",
    "\n",
    "medline_n = train_ml_ab_pos.shape[0]\n",
    "train_ml_ab_neg = raw.medline[~raw.medline.PMID.isin(raw_curated.PMID)].sample(medline_n)\n",
    "\n",
    "processed.train_ml_ab = pd.concat([train_ml_ab_neg, train_ml_ab_pos]).sample(frac=1)\n",
    "processed.train_ml_ab[\"DATASET\"] = \"train_ml_ab\"\n",
    "processed.train_ml_ab[[\"DATASET\", \"ORIGIN\", \"SOURCE\"]].groupby(\n",
    "    [\"DATASET\", \"SOURCE\"]\n",
    ").value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([processed.train_ml_ab, processed.test], axis=0) ['PMID'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write processed data to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write data/processed/pmid/test.ndjson\n",
      "Write data/processed/pmid/train_silver.ndjson\n",
      "Write data/processed/pmid/train_bronze.ndjson\n",
      "Write data/processed/pmid/train_silver_ab.ndjson\n",
      "Write data/processed/pmid/train_bronze_ab.ndjson\n",
      "Write data/processed/pmid/train_ml_ab.ndjson\n"
     ]
    }
   ],
   "source": [
    "for k in processed:\n",
    "    processed[k].to_json(cfg.data.processed.pmid[k], lines=True, orient='records')\n",
    "    print (f'Write {cfg.data.processed.pmid[k]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
