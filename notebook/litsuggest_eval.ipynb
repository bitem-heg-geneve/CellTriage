{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/CellTriage/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from base_fns import get_local_folder\n",
    "\n",
    "os.chdir(os.path.dirname(get_local_folder()))\n",
    "import pandas as pd\n",
    "import tabulate as tb\n",
    "from script.eval import evaluate\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import random\n",
    "from munch import Munch\n",
    "import numpy as np\n",
    "from pandarallel import pandarallel\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizerFast as BertTokenizer, BertModel\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "with initialize(\n",
    "    version_base=None,\n",
    "    config_path=\"../cfg\",\n",
    "):\n",
    "    cfg = compose(config_name=\"main\")\n",
    "\n",
    "random.seed(cfg.random.seed)\n",
    "np.random.seed(cfg.random.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/litsuggest/test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_silver= pd.read_csv('data/litsuggest/silver_test_pred.tsv', sep='\\t')\n",
    "test_silver['PRED'] = test_silver.apply(lambda row: 1 if row['SCORE'] >= 0.5 else 0, axis=1)\n",
    "test_silver = test_silver[['PMID', 'SCORE', 'PRED']].merge(test_df, how='left', on='PMID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<silver/litsuggest>>\n",
      "<<bronze/litsuggest>>\n"
     ]
    }
   ],
   "source": [
    "datasets={'silver': 'data/litsuggest/silver_test_pred.tsv', 'bronze':'data/litsuggest/bronze_test_pred.tsv'}\n",
    "results = {}\n",
    "for dataset, fp in datasets.items():\n",
    "    stub=f\"{dataset}/litsuggest\"\n",
    "    print(f\"<<{stub}>>\")\n",
    "    df = pd.read_csv(fp, sep='\\t')\n",
    "    df = df[['PMID', 'SCORE']].merge(test_df, how='left', on='PMID')\n",
    "    y_pred = pd.array(df['SCORE'])\n",
    "    y_true = pd.array(df['SOURCE'])\n",
    "    results[stub] = evaluate(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>P10</th>\n",
       "      <th>P100</th>\n",
       "      <th>P200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>silver/litsuggest</th>\n",
       "      <td>0.8378</td>\n",
       "      <td>0.9238</td>\n",
       "      <td>0.8787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bronze/litsuggest</th>\n",
       "      <td>0.6531</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>0.7752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   precision  recall      F1  P10  P100   P200\n",
       "silver/litsuggest     0.8378  0.9238  0.8787  1.0  0.99  0.985\n",
       "bronze/litsuggest     0.6531  0.9536  0.7752  1.0  0.94  0.900"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "RESULTS_FP = cfg.evaluation.litsuggest_eval.results_fp\n",
    "\n",
    "df =pd.DataFrame.from_dict(results, orient='index')\n",
    "with open(RESULTS_FP, \"w\") as f:\n",
    "    json_str = df.to_json(orient='records', lines=True)\n",
    "    f.write(json_str)\n",
    "    \n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
